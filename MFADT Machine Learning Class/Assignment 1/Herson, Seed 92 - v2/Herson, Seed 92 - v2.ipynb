{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Movie Review Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from my_measures import BinaryClassificationPerformance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('moviereviews_train.tsv', sep='\\t', quoting = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/main/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "Cleaning reviews: 100%|██████████████████| 25000/25000 [00:44<00:00, 565.58it/s]\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "nltk.download('stopwords')\n",
    "\n",
    "total_reviews = len(dataset['review'])  # This dynamically gets the total number of reviews\n",
    "\n",
    "corpus = []\n",
    "word_counts = []  # List to store word counts\n",
    "ps = PorterStemmer()  # Instantiate PorterStemmer once, before the loop\n",
    "stop_words = set(stopwords.words('english'))  # Call this once before the loop\n",
    "\n",
    "# Words to keep (negations and specific domain words)\n",
    "words_to_keep = {'not', \"isn't\", \"doesn't\", \"couldn't\", \"could not\", \"is not\", \"does not\", \"movie\", \"film\", \"cinema\"}\n",
    "\n",
    "# Remove these words from the stop_words set\n",
    "stop_words = stop_words.difference(words_to_keep)\n",
    "\n",
    "for i in tqdm(range(total_reviews), desc=\"Cleaning reviews: \"):\n",
    "    review = dataset['review'][i]\n",
    "    review = re.sub('[^a-zA-Z]', ' ', review)  # Keep only alphabetic characters\n",
    "    review = review.lower()  # Convert to lower case\n",
    "    review_words = review.split()  # Split into words\n",
    "    # Stem words not in stop_words\n",
    "    cleaned_review = [ps.stem(word) for word in review_words if word not in stop_words]\n",
    "    word_counts.append(len(cleaned_review))  # Count words after cleaning and stemming\n",
    "    cleaned_review = ' '.join(cleaned_review)  # Join words back into a single string\n",
    "    corpus.append(cleaned_review)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the sparse matrix | matrix of token counts | Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "# from sklearn.feature_extraction.text import HashingVectorizer\n",
    "cv = CountVectorizer(ngram_range=(1, 2))\n",
    "X_cv = cv.fit_transform(corpus)\n",
    "# hv = HashingVectorizer(n_features=2 ** 17, alternate_sign=False)\n",
    "# X_cv = hv.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a TF-IDF weighted document-term matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "transformer = TfidfTransformer()\n",
    "X_tfidf = transformer.fit_transform(X_cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating additional features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "from scipy.sparse import csr_matrix, hstack\n",
    "\n",
    "# 1. Get the count of tokens in the corpus\n",
    "# num_tokens = len(cv.vocabulary_)\n",
    "# print(f\"Number of tokens in the corpus: {num_tokens}\")\n",
    "\n",
    "word_counts_sparse = csr_matrix(word_counts).T  # Convert to CSR and transpose to a column vector\n",
    "\n",
    "punctuation_counts = dataset['review'].apply(lambda x: sum(c in string.punctuation for c in x))\n",
    "\n",
    "# Convert to a sparse matrix format\n",
    "punctuation_counts_sparse = csr_matrix(punctuation_counts).T  # Ensure it's a column\n",
    "\n",
    "# 2. Calculate token count per document\n",
    "# Summing across columns for each document (axis=1) gives the total token count per document\n",
    "# Ensure it remains a sparse matrix and transpose to column matrix\n",
    "token_counts_per_doc = csr_matrix(X_cv.sum(axis=1))\n",
    "\n",
    "# 3. Stack this feature with X_tfidf\n",
    "X_combined = hstack([X_tfidf]) #, punctuation_counts_sparse, word_counts_sparse])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the (scaled) matrix of features and the dependent variable vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler(with_mean=False)\n",
    "X = sc.fit_transform(X_combined)\n",
    "y = dataset['sentiment']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the dataset into 'train' and 'test' set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the models on the 'train' set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Pos': 9988, 'Neg': 10012, 'TP': 5352, 'TN': 4816, 'FP': 5196, 'FN': 4636, 'Accuracy': 0.5084, 'Precision': 0.5073947667804323, 'Recall': 0.5358430116139368, 'desc': 'ols_train'}\n"
     ]
    }
   ],
   "source": [
    "# Ordinary Least Squares\n",
    "\n",
    "from sklearn import linear_model\n",
    "ols = linear_model.SGDClassifier(loss=\"squared_error\")\n",
    "ols.fit(X_train, y_train)\n",
    "\n",
    "ols_performance_train = BinaryClassificationPerformance(ols.predict(X_train), y_train, 'ols_train')\n",
    "ols_performance_train.compute_measures()\n",
    "print(ols_performance_train.performance_measures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Pos': 9988, 'Neg': 10012, 'TP': 9988, 'TN': 10012, 'FP': 0, 'FN': 0, 'Accuracy': 1.0, 'Precision': 1.0, 'Recall': 1.0, 'desc': 'svm_train'}\n"
     ]
    }
   ],
   "source": [
    "# SVM, linear\n",
    "\n",
    "from sklearn import linear_model\n",
    "svm = linear_model.SGDClassifier()\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "svm_performance_train = BinaryClassificationPerformance(svm.predict(X_train), y_train, 'svm_train')\n",
    "svm_performance_train.compute_measures()\n",
    "print(svm_performance_train.performance_measures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Pos': 9988, 'Neg': 10012, 'TP': 9988, 'TN': 10012, 'FP': 0, 'FN': 0, 'Accuracy': 1.0, 'Precision': 1.0, 'Recall': 1.0, 'desc': 'lgs_train'}\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "\n",
    "from sklearn import linear_model\n",
    "lgs = linear_model.SGDClassifier(loss='log_loss')\n",
    "lgs.fit(X_train, y_train)\n",
    "\n",
    "lgs_performance_train = BinaryClassificationPerformance(lgs.predict(X_train), y_train, 'lgs_train')\n",
    "lgs_performance_train.compute_measures()\n",
    "print(lgs_performance_train.performance_measures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Pos': 9988, 'Neg': 10012, 'TP': 9988, 'TN': 10012, 'FP': 0, 'FN': 0, 'Accuracy': 1.0, 'Precision': 1.0, 'Recall': 1.0, 'desc': 'nbs_train'}\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nbs = MultinomialNB()\n",
    "nbs.fit(X_train, y_train)\n",
    "\n",
    "nbs_performance_train = BinaryClassificationPerformance(nbs.predict(X_train), y_train, 'nbs_train')\n",
    "nbs_performance_train.compute_measures()\n",
    "print(nbs_performance_train.performance_measures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Pos': 9988, 'Neg': 10012, 'TP': 9988, 'TN': 10012, 'FP': 0, 'FN': 0, 'Accuracy': 1.0, 'Precision': 1.0, 'Recall': 1.0, 'desc': 'prc_train'}\n"
     ]
    }
   ],
   "source": [
    "# Perceptron\n",
    "\n",
    "from sklearn import linear_model\n",
    "prc = linear_model.SGDClassifier(loss='perceptron')\n",
    "prc.fit(X_train, y_train)\n",
    "\n",
    "prc_performance_train = BinaryClassificationPerformance(prc.predict(X_train), y_train, 'prc_train')\n",
    "prc_performance_train.compute_measures()\n",
    "print(prc_performance_train.performance_measures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Pos': 9988, 'Neg': 10012, 'TP': 9988, 'TN': 10012, 'FP': 0, 'FN': 0, 'Accuracy': 1.0, 'Precision': 1.0, 'Recall': 1.0, 'desc': 'rdg_train'}\n"
     ]
    }
   ],
   "source": [
    "# Ridge Regression Classifier\n",
    "\n",
    "from sklearn import linear_model\n",
    "rdg = linear_model.RidgeClassifier()\n",
    "rdg.fit(X_train, y_train)\n",
    "\n",
    "rdg_performance_train = BinaryClassificationPerformance(rdg.predict(X_train), y_train, 'rdg_train')\n",
    "rdg_performance_train.compute_measures()\n",
    "print(rdg_performance_train.performance_measures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Pos': 9988, 'Neg': 10012, 'TP': 7474, 'TN': 7653, 'FP': 2359, 'FN': 2514, 'Accuracy': 0.75635, 'Precision': 0.7600935624936439, 'Recall': 0.7482979575490589, 'desc': 'rdf_train'}\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Classifier\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rdf = RandomForestClassifier(max_depth=2, random_state=90)\n",
    "rdf.fit(X_train, y_train)\n",
    "\n",
    "rdf_performance_train = BinaryClassificationPerformance(rdf.predict(X_train), y_train, 'rdf_train')\n",
    "rdf_performance_train.compute_measures()\n",
    "print(rdf_performance_train.performance_measures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting the 'test' set results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Pos': 2512, 'Neg': 2488, 'TP': 1346, 'TN': 1184, 'FP': 1304, 'FN': 1166, 'Accuracy': 0.506, 'Precision': 0.5079245283018868, 'Recall': 0.535828025477707, 'desc': 'ols_test'}\n"
     ]
    }
   ],
   "source": [
    "# Ordinary Least Squares\n",
    "\n",
    "ols_performance_test = BinaryClassificationPerformance(ols.predict(X_test), y_test, 'ols_test')\n",
    "ols_performance_test.compute_measures()\n",
    "print(ols_performance_test.performance_measures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Pos': 2512, 'Neg': 2488, 'TP': 2105, 'TN': 2025, 'FP': 463, 'FN': 407, 'Accuracy': 0.826, 'Precision': 0.8197040498442367, 'Recall': 0.8379777070063694, 'desc': 'svm_test'}\n"
     ]
    }
   ],
   "source": [
    "# SVM, linear\n",
    "\n",
    "svm_performance_test = BinaryClassificationPerformance(svm.predict(X_test), y_test, 'svm_test')\n",
    "svm_performance_test.compute_measures()\n",
    "print(svm_performance_test.performance_measures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Pos': 2512, 'Neg': 2488, 'TP': 2108, 'TN': 2041, 'FP': 447, 'FN': 404, 'Accuracy': 0.8298, 'Precision': 0.8250489236790607, 'Recall': 0.839171974522293, 'desc': 'lgs_test'}\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "\n",
    "lgs_performance_test = BinaryClassificationPerformance(lgs.predict(X_test), y_test, 'lgs_test')\n",
    "lgs_performance_test.compute_measures()\n",
    "print(lgs_performance_test.performance_measures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Pos': 2512, 'Neg': 2488, 'TP': 1968, 'TN': 2099, 'FP': 389, 'FN': 544, 'Accuracy': 0.8134, 'Precision': 0.8349596945269411, 'Recall': 0.7834394904458599, 'desc': 'nbs_test'}\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes\n",
    "\n",
    "nbs_performance_test = BinaryClassificationPerformance(nbs.predict(X_test), y_test, 'nbs_test')\n",
    "nbs_performance_test.compute_measures()\n",
    "print(nbs_performance_test.performance_measures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Pos': 2512, 'Neg': 2488, 'TP': 2073, 'TN': 2020, 'FP': 468, 'FN': 439, 'Accuracy': 0.8186, 'Precision': 0.8158205430932703, 'Recall': 0.8252388535031847, 'desc': 'prc_test'}\n"
     ]
    }
   ],
   "source": [
    "# Perceptron\n",
    "\n",
    "prc_performance_test = BinaryClassificationPerformance(prc.predict(X_test), y_test, 'prc_test')\n",
    "prc_performance_test.compute_measures()\n",
    "print(prc_performance_test.performance_measures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Pos': 2512, 'Neg': 2488, 'TP': 2300, 'TN': 2132, 'FP': 356, 'FN': 212, 'Accuracy': 0.8864, 'Precision': 0.8659638554216867, 'Recall': 0.9156050955414012, 'desc': 'rdg_test'}\n"
     ]
    }
   ],
   "source": [
    "# Ridge Regression Classifier\n",
    "\n",
    "rdg_performance_test = BinaryClassificationPerformance(rdg.predict(X_test), y_test, 'rdg_test')\n",
    "rdg_performance_test.compute_measures()\n",
    "print(rdg_performance_test.performance_measures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Pos': 2512, 'Neg': 2488, 'TP': 1838, 'TN': 1877, 'FP': 611, 'FN': 674, 'Accuracy': 0.743, 'Precision': 0.7505104124132299, 'Recall': 0.731687898089172, 'desc': 'rdf_test'}\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Classifier\n",
    "\n",
    "rdf_performance_test = BinaryClassificationPerformance(rdf.predict(X_test), y_test, 'rdf_test')\n",
    "rdf_performance_test.compute_measures()\n",
    "print(rdf_performance_test.performance_measures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making the Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
